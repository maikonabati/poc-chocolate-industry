{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_registros_prod = pd.read_excel(\"../../dist/registros-prod.xlsx\")\n",
    "df_analise_preditiva = pd.read_excel(\"../../dist/analise-preditiva.xlsx\")\n",
    "df_analise_prescritiva = pd.read_excel(\"../../dist/analise-prescritiva.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions & var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnc_Dummies(df):\n",
    "    for cat_feature in df.select_dtypes(include=['object']).columns:\n",
    "        df[cat_feature] = pd.Categorical(df[cat_feature]).codes\n",
    "        df[cat_feature] = df[cat_feature].replace(-1,np.nan)\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análise Descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipo de dados original\n",
    "df_registros_prod.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversão de variáveis categóricas\n",
    "df_registros_prod_v2 = fnc_Dummies(df_registros_prod.copy())\n",
    "df_registros_prod_v2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_registros_prod_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descritiva básica de features\n",
    "df_registros_prod_v2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas\n",
    "df_registros_prod_v2.hist(bins=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regressão Linear Simples (todos vs todos)\n",
    "lista = df_registros_prod_v2.columns\n",
    "for var_interesse in lista:\n",
    "    features_to_analyse = lista\n",
    "    fig, ax = plt.subplots(2, 2, figsize = (10,10))\n",
    "    for i, ax in enumerate(fig.axes):\n",
    "        if i < len(features_to_analyse):\n",
    "            sns.regplot(x=features_to_analyse[i],y=var_interesse, data=df_registros_prod_v2[features_to_analyse], ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análise Diagnóstica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Correlação de Pearson\n",
    "corr = df_registros_prod_v2.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(10, 220, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=True, annot_kws={\"size\": 15}, \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot com bucket/8 + faixa ideal para peso\n",
    "for var_boxplot in ['QTD_CHOC', 'VAR_1', 'VAR_2']:    \n",
    "    plt.figure(figsize = (10, 6))\n",
    "    ax = sns.boxplot(x=pd.cut(df_registros_prod_v2[var_boxplot], 8), y='PESO_BOMBOM', data=df_registros_prod_v2)\n",
    "    \n",
    "    # Faixa de peso ideal 9-10g\n",
    "    rect = plt.Rectangle((-1,9),100,1,color='green', alpha=0.1, ec='red')\n",
    "    ax.add_patch(rect)\n",
    "    ax.set_title(str(var_boxplot+' vs PESO_BOMBOM'))\n",
    "    \n",
    "    plt.setp(ax.artists, alpha=.5, linewidth=2, edgecolor=\"k\")\n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análise Preditiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo preditivo - GradientBoostingRegressor\n",
    "df_mqo_v3 = df_registros_prod_v2\n",
    "\n",
    "# Variáveis para treino\n",
    "feature_names = ['QTD_CHOC', 'VAR_1', 'VAR_2']\n",
    "target_name = ['PESO_BOMBOM']\n",
    "\n",
    "X = df_mqo_v3[feature_names]\n",
    "y = df_mqo_v3[target_name].values.ravel()\n",
    "\n",
    "# Separa dados para treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=50)\n",
    "\n",
    "# Prepara modelo para gráfico\n",
    "model = GradientBoostingRegressor()\n",
    "visualizer = ResidualsPlot(model)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean squared error\n",
    "train_model = model.fit(X,y)\n",
    "y_true = y\n",
    "y_pred = train_model.predict(X)\n",
    "print('MSE: ', mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparativo\n",
    "df_metric = pd.DataFrame(columns=['y_true','y_pred'])\n",
    "df_metric['y_true'] = y_true\n",
    "df_metric['y_pred'] = y_pred\n",
    "df_metric.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz cópia de dataset\n",
    "df_analise_preditiva_v2 = fnc_Dummies(df_analise_preditiva)\n",
    "\n",
    "# Variáveis para predict\n",
    "feature_names = ['QTD_CHOC', 'VAR_1', 'VAR_2']\n",
    "X_2 = df_analise_preditiva_v2[feature_names]\n",
    "\n",
    "# Carrega modelo para predict\n",
    "df_analise_preditiva_v2['PESO_BOMBOM'] = model.predict(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise_preditiva_v2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva predições\n",
    "writer = pd.ExcelWriter('../../dist/analise-preditiva-new.xlsx', engine='xlsxwriter')\n",
    "df_analise_preditiva_v2.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bônus - lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparando modelo Lime\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values,\n",
    "    feature_names=list(X_train.columns), \n",
    "    class_names=var_interesse,\n",
    "    verbose=True, \n",
    "    mode='regression'\n",
    ")\n",
    "\n",
    "# Define seed para modelo\n",
    "def explain(instance, predict_fn, **kwargs):\n",
    "  np.random.seed(50)\n",
    "  return explainer.explain_instance(instance, predict_fn, **kwargs)\n",
    "\n",
    "# Modelo de predição para teste\n",
    "i = 99\n",
    "exp = explain(X_test.values[i], train_model.predict, num_features=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Análise Prescritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
